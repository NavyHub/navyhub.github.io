<!DOCTYPE html>
<html lang="en">
  <head>
  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0">

  <title> 运行支持kubernetes原生调度的spark程序-Spark on Kubernetes - jimmysong.io|宋净超的博客|Cloud Native Developer Advocate</title>
  <meta name="description" content="jimmysong.io|宋净超的博客|Cloud Native Developer Advocate" />
  <meta property="og:title" content="运行支持kubernetes原生调度的spark程序-Spark on Kubernetes" />
  <meta name="twitter:title" content="运行支持kubernetes原生调度的spark程序-Spark on Kubernetes" />
  <meta name="description" content="TL;DR 关于 Spark on kubernetes 的详细信息和最新进展请见 jimmysong.io - spark-on-k8s 我们之前就在 kubernetes 中运行过 standalone 方式的 spark 集群，见 Spark standalone on kubernetes。 目前运行支持 kubernetes 原生调度的 spark 程序">
  <meta property="og:description" content="TL;DR 关于 Spark on kubernetes 的详细信息和最新进展请见 jimmysong.io - spark-on-k8s 我们之前就在 kubernetes 中运行过 standalone 方式的 spark 集群，见 Spark standalone on kubernetes。 目前运行支持 kubernetes 原生调度的 spark 程序">
  <meta name="twitter:description" content="TL;DR 关于 Spark on kubernetes 的详细信息和最新进展请见 jimmysong.io - spark-on-k8s 我们之前就在 kubernetes 中运行过 standalone 方式的 spark 集群，见 Spark standalone on kubernetes。 目前运行支持 kubernetes 原生调度的 spark 程序">
  <meta name="author" content="Jimmy Song(宋净超)"/>
  <link href='https://res.cloudinary.com/jimmysong/raw/upload/rootsongjc-hugo/favicon.ico' rel='icon' type='image/x-icon'/>
  <meta property="og:image" content="https://res.cloudinary.com/jimmysong/raw/upload/rootsongjc-hugo/avatar-icon.png" />
  <meta name="twitter:image" content="https://res.cloudinary.com/jimmysong/raw/upload/rootsongjc-hugo/avatar-icon.png" />
  <meta name="twitter:card" content="summary" />
  <meta name="twitter:site" content="@jimmysongio" />
  <meta name="twitter:creator" content="@jimmysongio" />
  <meta property="og:url" content="https://jimmysong.io/posts/running-spark-with-kubernetes-native-scheduler/" />
  <meta property="og:type" content="website" />
  <meta property="og:site_name" content="Jimmy Song" />

  <meta name="generator" content="Hugo 0.40" />
  <link rel="canonical" href="https://jimmysong.io/posts/running-spark-with-kubernetes-native-scheduler/" />
  <link rel="alternate" href="https://jimmysong.io/index.xml" type="application/rss+xml" title="Jimmy Song">
  <script src="https://res.cloudinary.com/jimmysong/raw/upload/rootsongjc-hugo/jquery-1.12.4.min.js"></script>
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.7.1/katex.min.css" integrity="sha384-wITovz90syo1dJWVh32uuETPVEtGigN07tkttEqPv+uR2SE/mbQcG7ATL28aI9H0" crossorigin="anonymous">
  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css" />
  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css" integrity="sha384-BVYiiSIFeK1dGmJRAkycuHAHRg32OmUcww7on3RYdg4Va+PmSTsz/K68vbdEjh4u" crossorigin="anonymous">
  
  
  <link rel="stylesheet" href="https://jimmysong.io/css/main.css" />
  <link rel="stylesheet" href="https://jimmysong.io/css/search.css" />
  
  

<meta name="baidu-site-verification" content="g8IYR9SNLF" />
<script>
    var _hmt = _hmt || [];
    (function() {
    var hm = document.createElement("script");
    hm.src = "https://hm.baidu.com/hm.js?11f7d254cfa4e0ca44b175c66d379ecc";
    var s = document.getElementsByTagName("script")[0];
    s.parentNode.insertBefore(hm, s);
    })();
</script>

<link rel="stylesheet" href="https://jimmysong.io/css/prism.css" />




<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/photoswipe/4.1.1/photoswipe.min.css" integrity="sha256-sCl5PUOGMLfFYctzDW3MtRib0ctyUvI9Qsmq2wXOeBY=" crossorigin="anonymous" />
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/photoswipe/4.1.1/default-skin/default-skin.min.css" integrity="sha256-BFeI1V+Vh1Rk37wswuOYn5lsTcaU96hGaI7OUVCLjPc=" crossorigin="anonymous" />



<div class="pswp" tabindex="-1" role="dialog" aria-hidden="true">

<div class="pswp__bg"></div>

<div class="pswp__scroll-wrap">
    
    <div class="pswp__container">
      <div class="pswp__item"></div>
      <div class="pswp__item"></div>
      <div class="pswp__item"></div>
    </div>
    
    <div class="pswp__ui pswp__ui--hidden">
    <div class="pswp__top-bar">
      
      <div class="pswp__counter"></div>
      <button class="pswp__button pswp__button--close" title="Close (Esc)"></button>
      <button class="pswp__button pswp__button--share" title="Share"></button>
      <button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>
      <button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button>
      
      
      <div class="pswp__preloader">
        <div class="pswp__preloader__icn">
          <div class="pswp__preloader__cut">
            <div class="pswp__preloader__donut"></div>
          </div>
        </div>
      </div>
    </div>
    <div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap">
      <div class="pswp__share-tooltip"></div>
    </div>
    <button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
    </button>
    <button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)">
    </button>
    <div class="pswp__caption">
      <div class="pswp__caption__center"></div>
    </div>
    </div>
    </div>
</div>

</head>

  <body>
    <nav class="navbar navbar-default navbar-fixed-top navbar-custom">
  <div class="container-fluid">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle" data-toggle="collapse" data-target="#main-navbar">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="https://jimmysong.io/">Jimmy Song</a>
    </div>
    <div class="collapse navbar-collapse" id="main-navbar">
      <ul class="nav navbar-nav navbar-right">
        
          
            <li class="navlinks-container">
              <a class="navlinks-parent" href="javascript:void(0)">Categories</a>
              <div class="navlinks-children">
                
                
                  <a href="https://jimmysong.io/categories/kubernetes">kubernetes</a>
                
                
                  <a href="https://jimmysong.io/categories/cloud-native">Cloud Native</a>
                
                
                  <a href="https://jimmysong.io/categories/microservices">Microservices</a>
                
                
                  <a href="https://jimmysong.io/categories/devops">Devops</a>
                
                
                  <a href="https://jimmysong.io/categories/github">Github</a>
                
                
                  <a href="https://jimmysong.io/categories/serverless">Serverless</a>
                
                
                  <a href="https://jimmysong.io/categories/service-mesh">Service Mesh</a>
                
                
                  <a href="https://jimmysong.io/tags">Tags</a>
                
              </div>
            </li>
          
        
          
            <li class="navlinks-container">
              <a class="navlinks-parent" href="javascript:void(0)">Gitbooks</a>
              <div class="navlinks-children">
                
                
                  <a href="https://jimmysong.io/kubernetes-handbook">Kubernetes handbook</a>
                
                
                  <a href="https://jimmysong.io/docker-handbook">Docker handbook</a>
                
                
                  <a href="https://jimmysong.io/hugo-handbook">Hugo Handbook</a>
                
                
                  <a href="https://servicemesher.github.io/envoy">Envoy proxy中文文档</a>
                
                
                  <a href="https://jimmysong.io/migrating-to-cloud-native-application-architectures">Migrating to Cloud Native</a>
                
              </div>
            </li>
          
        
          
            <li class="navlinks-container">
              <a class="navlinks-parent" href="javascript:void(0)">Publications</a>
              <div class="navlinks-children">
                
                
                  <a href="https://jimmysong.io/cloud-native-go">Cloud Native Go</a>
                
                
                  <a href="https://jimmysong.io/posts/cloud-native-python">Cloud Native Python</a>
                
                
                  <a href="https://jimmysong.io/posts/cloud-native-java">Cloud Native Java</a>
                
              </div>
            </li>
          
        
          
            <li class="navlinks-container">
              <a class="navlinks-parent" href="javascript:void(0)">Projects</a>
              <div class="navlinks-children">
                
                
                  <a href="https://github.com/rootsongjc/kubernetes-vagrant-centos-cluster">k8s all-in-one</a>
                
                
                  <a href="https://jimmysong.io/spark-on-k8s">Spark on kubernetes</a>
                
                
                  <a href="https://jimmysong.io/posts/yarn-on-docker">Magpie</a>
                
                
                  <a href="https://jimmysong.io/cheatsheets">Cheatsheets</a>
                
                
                  <a href="https://github.com/rootsongjc/beautifulhugo">Beautifulhugo</a>
                
              </div>
            </li>
          
        
          
            <li>
              <a title="About" href="/about">About</a>
              
              
            </li>
          
        

        

        
        
          <li>
            <a href="#modalSearch" data-toggle="modal" data-target="#modalSearch" style="outline: none;">
              <span class="hidden-sm hidden-md hidden-lg">Search</span> <span id="searchGlyph" class="glyphicon glyphicon-search"></span>
            </a>
          </li>
          
      </ul>
    </div>

    <div class="avatar-container">
      <div class="avatar-img-border">
        
          <a title="Jimmy Song" href="https://jimmysong.io/">
            <img class="avatar-img" src="https://res.cloudinary.com/jimmysong/raw/upload/rootsongjc-hugo/avatar-icon.png" alt="Jimmy Song" />
          </a>
        
      </div>
    </div>

  </div>
</nav>





  <div id="modalSearch" class="modal fade" role="dialog">
    <div class="modal-dialog">
      <div class="modal-content">
        <div class="modal-header">
          <button type="button" class="close" data-dismiss="modal">&times;</button>
          <h4 class="modal-title">Search jimmysong.io</h4>
        </div>
        <div class="modal-body">
            
<div class="aa-input-container" id="aa-input-container">
    <input type="search" id="aa-search-input" class="aa-input-search" placeholder="Search for titles or URIs..." name="search" autocomplete="off" />
    <svg class="aa-input-icon" viewBox="654 -372 1664 1664">
        <path d="M1806,332c0-123.3-43.8-228.8-131.5-316.5C1586.8-72.2,1481.3-116,1358-116s-228.8,43.8-316.5,131.5  C953.8,103.2,910,208.7,910,332s43.8,228.8,131.5,316.5C1129.2,736.2,1234.7,780,1358,780s228.8-43.8,316.5-131.5  C1762.2,560.8,1806,455.3,1806,332z M2318,1164c0,34.7-12.7,64.7-38,90s-55.3,38-90,38c-36,0-66-12.7-90-38l-343-342  c-119.3,82.7-252.3,124-399,124c-95.3,0-186.5-18.5-273.5-55.5s-162-87-225-150s-113-138-150-225S654,427.3,654,332  s18.5-186.5,55.5-273.5s87-162,150-225s138-113,225-150S1262.7-372,1358-372s186.5,18.5,273.5,55.5s162,87,225,150s113,138,150,225  S2062,236.7,2062,332c0,146.7-41.3,279.7-124,399l343,343C2305.7,1098.7,2318,1128.7,2318,1164z" />
    </svg>
</div>



<script src="https://res.cloudinary.com/jimmysong/raw/upload/rootsongjc-hugo/algoliasearch.min.js"></script>
<script src="https://res.cloudinary.com/jimmysong/raw/upload/rootsongjc-hugo/autocomplete.min.js"></script>

<script>
var client = algoliasearch("X4YB3WOBNV", "d2134c5a8d250e6d3246594240c45201");
var index = client.initIndex('rootsongjc-hugo');

autocomplete('#aa-search-input',
{ hint: false}, {
    source: autocomplete.sources.hits(index, {hitsPerPage: 5}),
    
    displayKey: 'name',
    
    templates: {
        
        suggestion: function(suggestion) {
            
            return '<span>' + '<a href="/' + suggestion.uri+ '">' +
            suggestion._highlightResult.title.value + '</a></span>';
        }
    }
});
</script>


        </div>
        <div class="modal-footer">
          <button type="button" class="btn btn-default" data-dismiss="modal">close</button>
        </div>
      </div>
    </div>
  </div>


    
  
  
  




  

  <header class="header-section ">
    
    <div class="intro-header no-img">
      
      <div class="container">
        <div class="row">
          <div class="col-lg-12 col-md-12 col-md-offset-0">
            <div class="posts-heading">
                <h1 align="center">运行支持kubernetes原生调度的spark程序-Spark on Kubernetes</h1>
                
                
            </div>
          </div>
        </div>
      </div>
    </div>
  </header>


    
<div class="container" role="main" itemscope itemtype="http://schema.org/Article">
    <div class="row">
        <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
            
            
            
<div>
    <section id="datecount">
        <h4 id="date"> Thu Sep 14, 2017</h4>
    </section>
    <h5 id="wc">4200 Words|Read in about 9 Min</h5>
    <h5 id="tags">Tags: 
        
        <a href="https://jimmysong.io/tags/kubernetes/">kubernetes</a> &nbsp;
        
        <a href="https://jimmysong.io/tags/spark/">spark</a> &nbsp;
        
        <a href="https://jimmysong.io/tags/big-data/">big-data</a> &nbsp;
    </h5>
</div>

            
            <article role="main" class="blog-post" itemprop="articleBody" id="content">
                
  
  <aside class="toc">
    <nav id="TableOfContents">
<ul>
<li>
<ul>
<li><a href="#spark-概念说明">Spark 概念说明</a>
<ul>
<li><a href="#动态资源分配策略">动态资源分配策略</a></li>
</ul></li>
<li><a href="#架构设计">架构设计</a>
<ul>
<li><a href="#调度器后台">调度器后台</a></li>
</ul></li>
<li><a href="#安装指南">安装指南</a></li>
<li><a href="#开发文档">开发文档</a>
<ul>
<li><a href="#编译">编译</a></li>
<li><a href="#构建镜像">构建镜像</a></li>
</ul></li>
<li><a href="#运行测试">运行测试</a></li>
<li><a href="#依赖管理">依赖管理</a>
<ul>
<li>
<ul>
<li><a href="#创建-resource-staging-server">创建 resource staging server</a></li>
<li><a href="#优化">优化</a></li>
<li><a href="#设置-hdfs-用户">设置 HDFS 用户</a></li>
</ul></li>
</ul></li>
<li><a href="#参考">参考</a></li>
</ul></li>
</ul>
</nav>
  </aside>
  


                

<p>TL;DR 关于 Spark on kubernetes 的详细信息和最新进展请见 <a href="https://jimmysong.io/spark-on-k8s">jimmysong.io - spark-on-k8s</a></p>

<p>我们之前就在 kubernetes 中运行过 standalone 方式的 spark 集群，见 <a href="https://jimmysong.io/kubernetes-handbook/usecases/spark-standalone-on-kubernetes.html">Spark standalone on kubernetes</a>。</p>

<p>目前运行支持 kubernetes 原生调度的 spark 程序项目由 Google 主导，fork 自 spark 的官方代码库，见 <a href="https://github.com/apache-spark-on-k8s/spark/">GitHub - spark-on-k8s</a> ，属于Big Data SIG。</p>

<p>参与到该项目的公司有：</p>

<ul>
<li>Bloomberg</li>
<li>Google</li>
<li>Haiwen</li>
<li>Hyperpilot</li>
<li>Intel</li>
<li>Palantir</li>
<li>Pepperdata</li>
<li>Red Hat</li>
</ul>

<h2 id="spark-概念说明">Spark 概念说明</h2>

<p><a href="http://spark.apache.org">Apache Spark</a> 是一个围绕速度、易用性和复杂分析构建的大数据处理框架。最初在2009年由加州大学伯克利分校的AMPLab开发，并于2010年成为Apache的开源项目之一。</p>

<p>在 Spark 中包括如下组件或概念：</p>

<ul>
<li><p><strong>Application</strong>：Spark Application 的概念和 Hadoop 中的 MapReduce 类似，指的是用户编写的 Spark 应用程序，包含了一个 Driver 功能的代码和分布在集群中多个节点上运行的 Executor 代码；</p></li>

<li><p><strong>Driver</strong>：Spark 中的 Driver 即运行上述 Application 的 main() 函数并且创建 SparkContext，其中创建 SparkContext 的目的是为了准备Spark应用程序的运行环境。在 Spark 中由 SparkContext 负责和 ClusterManager 通信，进行资源的申请、任务的分配和监控等；当 Executor 部分运行完毕后，Driver负责将SparkContext 关闭。通常用 SparkContext 代表 Driver；</p></li>

<li><p><strong>Executor</strong>：Application运行在Worker 节点上的一个进程，该进程负责运行Task，并且负责将数据存在内存或者磁盘上，每个Application都有各自独立的一批Executor。在Spark on Yarn模式下，其进程名称为<code>CoarseGrainedExecutorBackend</code>，类似于 Hadoop MapReduce 中的 YarnChild。一个 <code>CoarseGrainedExecutorBackend</code> 进程有且仅有一个 executor 对象，它负责将 Task 包装成 taskRunner，并从线程池中抽取出一个空闲线程运行 Task。每个 <code>CoarseGrainedExecutorBackend</code> 能并行运行 Task 的数量就取决于分配给它的 CPU 的个数了；</p></li>

<li><p><strong>Cluster Manager</strong>：指的是在集群上获取资源的外部服务，目前有：</p>

<ul>
<li>Standalone：Spark原生的资源管理，由Master负责资源的分配；</li>
<li>Hadoop Yarn：由YARN中的ResourceManager负责资源的分配；</li>
</ul></li>

<li><p><strong>Worker</strong>：集群中任何可以运行Application代码的节点，类似于YARN中的NodeManager节点。在Standalone模式中指的就是通过Slave文件配置的Worker节点，在Spark on Yarn模式中指的就是NodeManager节点；</p></li>

<li><p><strong>作业（Job）</strong>：包含多个Task组成的并行计算，往往由Spark Action催生，一个JOB包含多个RDD及作用于相应RDD上的各种Operation；</p></li>

<li><p><strong>阶段（Stage）</strong>：每个Job会被拆分很多组 Task，每组任务被称为Stage，也可称TaskSet，一个作业分为多个阶段，每一个stage的分割点是action。比如一个job是：（transformation1 -&gt; transformation1 -&gt; action1 -&gt; transformation3 -&gt; action2），这个job就会被分为两个stage，分割点是action1和action2。</p></li>

<li><p><strong>任务（Task）</strong>： 被送到某个Executor上的工作任务；</p></li>

<li><p><strong>Context</strong>：启动spark application的时候创建，作为Spark 运行时环境。</p></li>

<li><p><strong>Dynamic Allocation（动态资源分配）</strong>：一个配置选项，可以将其打开。从Spark1.2之后，对于On Yarn模式，已经支持动态资源分配（Dynamic Resource Allocation），这样，就可以根据Application的负载（Task情况），动态的增加和减少executors，这种策略非常适合在YARN上使用spark-sql做数据开发和分析，以及将spark-sql作为长服务来使用的场景。Executor 的动态分配需要在 cluster mode 下启用 &ldquo;external shuffle service&rdquo;。</p></li>
</ul>

<h3 id="动态资源分配策略">动态资源分配策略</h3>

<p>开启动态分配策略后，application会在task因没有足够资源被挂起的时候去动态申请资源，这意味着该application现有的executor无法满足所有task并行运行。spark一轮一轮的申请资源，当有task挂起或等待</p>

<pre><code class="language-ini">  spark.dynamicAllocation.schedulerBacklogTimeout
</code></pre>

<p>(默认1s)时间的时候，会开始动态资源分配；之后会每隔</p>

<pre><code class="language-ini">  spark.dynamicAllocation.sustainedSchedulerBacklogTimeout
</code></pre>

<p>(默认1s)时间申请一次，直到申请到足够的资源。每次申请的资源量是指数增长的，即1,2,4,8等。之所以采用指数增长，出于两方面考虑：其一，开始申请的少是考虑到可能application会马上得到满足；其次要成倍增加，是为了防止application需要很多资源，而该方式可以在很少次数的申请之后得到满足。</p>

<h2 id="架构设计">架构设计</h2>

<p>关于 spark standalone 的局限性与 kubernetes native spark 架构之间的区别请参考 Anirudh Ramanathan 在 2016年10月8日提交的 issue <a href="https://github.com/kubernetes/kubernetes/issues/34377">Support Spark natively in Kubernetes #34377</a>。</p>

<p>简而言之，spark standalone on kubernetes 有如下几个缺点：</p>

<ul>
<li>无法对于多租户做隔离，每个用户都想给 pod 申请 node 节点可用的最大的资源。</li>
<li>Spark 的 master／worker 本来不是设计成使用 kubernetes 的资源调度，这样会存在两层的资源调度问题，不利于与 kuberentes 集成。</li>
</ul>

<p>而 kubernetes native spark 集群中，spark 可以调用 kubernetes API 获取集群资源和调度。要实现 kubernetes native spark 需要为 spark 提供一个集群外部的 manager 可以用来跟 kubernetes API 交互。</p>

<h3 id="调度器后台">调度器后台</h3>

<p>使用 kubernetes 原生调度的 spark 的基本设计思路是将 spark 的 driver 和 executor 都放在 kubernetes 的 pod 中运行，另外还有两个附加的组件：<code>ResourceStagingServer</code> 和 <code>KubernetesExternalShuffleService</code>。</p>

<p>Spark driver 其实可以运行在 kubernetes 集群内部（cluster mode）可以运行在外部（client mode），executor 只能运行在集群内部，当有 spark 作业提交到 kubernetes 集群上时，调度器后台将会为 executor pod 设置如下属性：</p>

<ul>
<li>使用我们预先编译好的包含 kubernetes 支持的 spark 镜像，然后调用 <code>CoarseGrainedExecutorBackend</code> main class 启动 JVM。</li>
<li>调度器后台为 executor pod 的运行时注入环境变量，例如各种 JVM 参数，包括用户在 <code>spark-submit</code> 时指定的那些参数。</li>
<li>Executor 的 CPU、内存限制根据这些注入的环境变量保存到应用程序的 <code>SparkConf</code> 中。</li>
<li>可以在配置中指定 spark 运行在指定的 namespace 中。</li>
</ul>

<p>参考：<a href="https://github.com/apache-spark-on-k8s/spark/blob/branch-2.2-kubernetes/resource-managers/kubernetes/architecture-docs/scheduler-backend.md">Scheduler backend 文档</a></p>

<h2 id="安装指南">安装指南</h2>

<p>我们可以直接使用官方已编译好的 docker 镜像来部署，下面是官方发布的镜像：</p>

<table>
<thead>
<tr>
<th>组件</th>
<th>镜像</th>
</tr>
</thead>

<tbody>
<tr>
<td>Spark Driver Image</td>
<td><code>kubespark/spark-driver:v2.1.0-kubernetes-0.3.1</code></td>
</tr>

<tr>
<td>Spark Executor Image</td>
<td><code>kubespark/spark-executor:v2.1.0-kubernetes-0.3.1</code></td>
</tr>

<tr>
<td>Spark Initialization Image</td>
<td><code>kubespark/spark-init:v2.1.0-kubernetes-0.3.1</code></td>
</tr>

<tr>
<td>Spark Staging Server Image</td>
<td><code>kubespark/spark-resource-staging-server:v2.1.0-kubernetes-0.3.1</code></td>
</tr>

<tr>
<td>PySpark Driver Image</td>
<td><code>kubespark/driver-py:v2.1.0-kubernetes-0.3.1</code></td>
</tr>

<tr>
<td>PySpark Executor Image</td>
<td><code>kubespark/executor-py:v2.1.0-kubernetes-0.3.1</code></td>
</tr>
</tbody>
</table>

<p>我将这些镜像放到了我的私有镜像仓库中了。</p>

<p>还需要安装支持 kubernetes 的 spark 客户端，在<a href="https://github.com/apache-spark-on-k8s/spark/releases">这里下载</a></p>

<p>根据使用的镜像版本，我下载的是 <a href="https://github.com/apache-spark-on-k8s/spark/releases/tag/v2.1.0-kubernetes-0.3.1">v2.1.0-kubernetes-0.3.1</a></p>

<p><strong>运行 SparkPi 测试</strong></p>

<pre><code class="language-bash">./bin/spark-submit \
  --deploy-mode cluster \
  --class org.apache.spark.examples.SparkPi \
  --master k8s://https://172.20.0.113:6443 \
  --kubernetes-namespace spark-cluster \
  --conf spark.executor.instances=5 \
  --conf spark.app.name=spark-pi \
  --conf spark.kubernetes.driver.docker.image=sz-pg-oam-docker-hub-001.tendcloud.com/library/kubespark-spark-driver:v2.1.0-kubernetes-0.3.1 \
  --conf spark.kubernetes.executor.docker.image=sz-pg-oam-docker-hub-001.tendcloud.com/library/kubespark-spark-executor:v2.1.0-kubernetes-0.3.1 \
  --conf spark.kubernetes.initcontainer.docker.image=sz-pg-oam-docker-hub-001.tendcloud.com/library/kubespark-spark-init:v2.1.0-kubernetes-0.3.1 \
local:///opt/spark/examples/jars/spark-examples_2.11-2.1.0-k8s-0.3.1-SNAPSHOT.jar
</code></pre>

<p>关于该命令参数的介绍请参考：<a href="https://apache-spark-on-k8s.github.io/userdocs/running-on-kubernetes.html">running on kubernetes</a></p>

<p><strong>注意：</strong> 该 jar 包实际上是</p>

<pre><code class="language-ini">spark.kubernetes.executor.docker.image
</code></pre>

<p>镜像中的。</p>

<p>这时候提交任务运行还是失败，报错信息中可以看到两个问题：</p>

<ul>
<li>Executor 无法找到 driver pod</li>
<li>用户 <code>system:serviceaccount:spark-cluster:defaul</code> 没有权限获取 <code>spark-cluster</code> 中的 pod 信息。</li>
</ul>

<p>提了个 issue <a href="https://github.com/apache-spark-on-k8s/spark/issues/478">Failed to run the sample spark-pi test using spark-submit on the doc #478</a></p>

<p>需要为 spark 集群创建一个 <code>serviceaccount</code> 和 <code>clusterrolebinding</code>：</p>

<pre><code class="language-bash">kubectl create serviceaccount spark --namespace spark-cluster
kubectl create rolebinding spark-edit --clusterrole=edit --serviceaccount=spark-cluster:spark --namespace=spark-cluster
</code></pre>

<p>该 Bug 将在新版本中修复。</p>

<h2 id="开发文档">开发文档</h2>

<h3 id="编译">编译</h3>

<p>Fork 并克隆项目到本地：</p>

<pre><code class="language-bash">git clone https://github.com/rootsongjc/spark.git
</code></pre>

<p>编译前请确保你的环境中已经安装 Java8 和 Maven3。</p>

<pre><code class="language-bash">## 第一次编译前需要安装依赖
build/mvn install -Pkubernetes -pl resource-managers/kubernetes/core -am -DskipTests

## 编译 spark on kubernetes
build/mvn compile -Pkubernetes -pl resource-managers/kubernetes/core -am -DskipTests

## 发布
dev/make-distribution.sh --tgz -Phadoop-2.7 -Pkubernetes
</code></pre>

<p>第一次编译和发布的过程耗时可能会比较长，请耐心等待，如果有依赖下载不下来，请自备梯子。</p>

<p>参阅 <a href="https://github.com/apache-spark-on-k8s/spark/blob/branch-2.2-kubernetes/resource-managers/kubernetes/README.md">详细的开发指南</a></p>

<h3 id="构建镜像">构建镜像</h3>

<p><a href="https://github.com/apache-spark-on-k8s/spark/pull/488">使用该脚本来自动构建容器镜像</a></p>

<p>将该脚本放在 <code>dist</code> 目录下，执行：</p>

<pre><code class="language-bash">./build-push-docker-images.sh -r sz-pg-oam-docker-hub-001.tendcloud.com/library -t v2.1.0-kubernetes-0.3.1-1 build
./build-push-docker-images.sh -r sz-pg-oam-docker-hub-001.tendcloud.com/library -t v2.1.0-kubernetes-0.3.1-1 push
</code></pre>

<p><strong>注意：</strong>如果你使用的 MacOS，bash 的版本可能太低，执行改脚本将出错，请检查你的 bash 版本：</p>

<pre><code class="language-bash">bash --version
GNU bash, version 3.2.57(1)-release (x86_64-apple-darwin16)
Copyright (C) 2007 Free Software Foundation, Inc.
</code></pre>

<p>上面我在升级 bash 之前获取的版本信息，使用下面的命令升级 bash：</p>

<pre><code class="language-bash">brew install bash
</code></pre>

<p>升级后的 bash 版本为 <code>4.4.12(1)-release (x86_64-apple-darwin16.3.0)</code>。</p>

<p>编译并上传镜像到我的私有镜像仓库，将会构建出如下几个镜像：</p>

<pre><code class="language-bash">sz-pg-oam-docker-hub-001.tendcloud.com/library/spark-driver:v2.1.0-kubernetes-0.3.1-1
sz-pg-oam-docker-hub-001.tendcloud.com/library/spark-resource-staging-server:v2.1.0-kubernetes-0.3.1-1
sz-pg-oam-docker-hub-001.tendcloud.com/library/spark-init:v2.1.0-kubernetes-0.3.1-1
sz-pg-oam-docker-hub-001.tendcloud.com/library/spark-shuffle:v2.1.0-kubernetes-0.3.1-1
sz-pg-oam-docker-hub-001.tendcloud.com/library/spark-executor:v2.1.0-kubernetes-0.3.1-1
sz-pg-oam-docker-hub-001.tendcloud.com/library/spark-executor-py:v2.1.0-kubernetes-0.3.1-1
sz-pg-oam-docker-hub-001.tendcloud.com/library/spark-driver-py:v2.1.0-kubernetes-0.3.1-1
</code></pre>

<h2 id="运行测试">运行测试</h2>

<p>在 <code>dist/bin</code> 目录下执行 spark-pi 测试：</p>

<pre><code class="language-bash">./spark-submit \
  --deploy-mode cluster \
  --class org.apache.spark.examples.SparkPi \
  --master k8s://https://172.20.0.113:6443 \
  --kubernetes-namespace spark-cluster \
  --conf spark.kubernetes.authenticate.driver.serviceAccountName=spark \
  --conf spark.executor.instances=5 \
  --conf spark.app.name=spark-pi \
  --conf spark.kubernetes.driver.docker.image=sz-pg-oam-docker-hub-001.tendcloud.com/library/spark-driver:v2.1.0-kubernetes-0.3.1-1 \
  --conf spark.kubernetes.executor.docker.image=sz-pg-oam-docker-hub-001.tendcloud.com/library/spark-executor:v2.1.0-kubernetes-0.3.1-1 \
  --conf spark.kubernetes.initcontainer.docker.image=sz-pg-oam-docker-hub-001.tendcloud.com/library/spark-init:v2.1.0-kubernetes-0.3.1-1 \
local:///opt/spark/examples/jars/spark-examples_2.11-2.2.0-k8s-0.4.0-SNAPSHOT.jar
</code></pre>

<p>详细的参数说明见 <a href="https://apache-spark-on-k8s.github.io/userdocs/running-on-kubernetes.html">running on kubernetes</a></p>

<p><strong>注意</strong></p>

<pre><code>local:///opt/spark/examples/jars/spark-examples_2.11-2.2.0-k8s-0.4.0-SNAPSHOT.jar
</code></pre>

<p>文件是在spark-driver和spark-executor镜像里的，在上一步构建镜像时已经构建并上传到了镜像仓库中。</p>

<p>执行日志显示：</p>

<pre><code class="language-bash">2017-09-14 14:59:01 INFO  Client:54 - Waiting for application spark-pi to finish...
2017-09-14 14:59:01 INFO  LoggingPodStatusWatcherImpl:54 - State changed, new state:
	 pod name: spark-pi-1505372339796-driver
	 namespace: spark-cluster
	 labels: spark-app-selector -&gt; spark-f4d3a5d3ad964a05a51feb6191d50357, spark-role -&gt; driver
	 pod uid: 304cf440-991a-11e7-970c-f4e9d49f8ed0
	 creation time: 2017-09-14T06:59:01Z
	 service account name: spark
	 volumes: spark-token-zr8wv
	 node name: N/A
	 start time: N/A
	 container images: N/A
	 phase: Pending
	 status: []
2017-09-14 14:59:01 INFO  LoggingPodStatusWatcherImpl:54 - State changed, new state:
	 pod name: spark-pi-1505372339796-driver
	 namespace: spark-cluster
	 labels: spark-app-selector -&gt; spark-f4d3a5d3ad964a05a51feb6191d50357, spark-role -&gt; driver
	 pod uid: 304cf440-991a-11e7-970c-f4e9d49f8ed0
	 creation time: 2017-09-14T06:59:01Z
	 service account name: spark
	 volumes: spark-token-zr8wv
	 node name: 172.20.0.114
	 start time: N/A
	 container images: N/A
	 phase: Pending
	 status: []
2017-09-14 14:59:01 INFO  LoggingPodStatusWatcherImpl:54 - State changed, new state:
	 pod name: spark-pi-1505372339796-driver
	 namespace: spark-cluster
	 labels: spark-app-selector -&gt; spark-f4d3a5d3ad964a05a51feb6191d50357, spark-role -&gt; driver
	 pod uid: 304cf440-991a-11e7-970c-f4e9d49f8ed0
	 creation time: 2017-09-14T06:59:01Z
	 service account name: spark
	 volumes: spark-token-zr8wv
	 node name: 172.20.0.114
	 start time: 2017-09-14T06:59:01Z
	 container images: sz-pg-oam-docker-hub-001.tendcloud.com/library/spark-driver:v2.1.0-kubernetes-0.3.1-1
	 phase: Pending
	 status: [ContainerStatus(containerID=null, image=sz-pg-oam-docker-hub-001.tendcloud.com/library/spark-driver:v2.1.0-kubernetes-0.3.1-1, imageID=, lastState=ContainerState(running=null, terminated=null, waiting=null, additionalProperties={}), name=spark-kubernetes-driver, ready=false, restartCount=0, state=ContainerState(running=null, terminated=null, waiting=ContainerStateWaiting(message=null, reason=ContainerCreating, additionalProperties={}), additionalProperties={}), additionalProperties={})]
2017-09-14 14:59:03 INFO  LoggingPodStatusWatcherImpl:54 - State changed, new state:
	 pod name: spark-pi-1505372339796-driver
	 namespace: spark-cluster
	 labels: spark-app-selector -&gt; spark-f4d3a5d3ad964a05a51feb6191d50357, spark-role -&gt; driver
	 pod uid: 304cf440-991a-11e7-970c-f4e9d49f8ed0
	 creation time: 2017-09-14T06:59:01Z
	 service account name: spark
	 volumes: spark-token-zr8wv
	 node name: 172.20.0.114
	 start time: 2017-09-14T06:59:01Z
	 container images: sz-pg-oam-docker-hub-001.tendcloud.com/library/spark-driver:v2.1.0-kubernetes-0.3.1-1
	 phase: Running
	 status: [ContainerStatus(containerID=docker://5c5c821c482a1e35552adccb567020532b79244392374f25754f0050e6cd4c62, image=sz-pg-oam-docker-hub-001.tendcloud.com/library/spark-driver:v2.1.0-kubernetes-0.3.1-1, imageID=docker-pullable://sz-pg-oam-docker-hub-001.tendcloud.com/library/spark-driver@sha256:beb92a3e3f178e286d9e5baebdead88b5ba76d651f347ad2864bb6f8eda26f94, lastState=ContainerState(running=null, terminated=null, waiting=null, additionalProperties={}), name=spark-kubernetes-driver, ready=true, restartCount=0, state=ContainerState(running=ContainerStateRunning(startedAt=2017-09-14T06:59:02Z, additionalProperties={}), terminated=null, waiting=null, additionalProperties={}), additionalProperties={})]
2017-09-14 14:59:12 INFO  LoggingPodStatusWatcherImpl:54 - State changed, new state:
	 pod name: spark-pi-1505372339796-driver
	 namespace: spark-cluster
	 labels: spark-app-selector -&gt; spark-f4d3a5d3ad964a05a51feb6191d50357, spark-role -&gt; driver
	 pod uid: 304cf440-991a-11e7-970c-f4e9d49f8ed0
	 creation time: 2017-09-14T06:59:01Z
	 service account name: spark
	 volumes: spark-token-zr8wv
	 node name: 172.20.0.114
	 start time: 2017-09-14T06:59:01Z
	 container images: sz-pg-oam-docker-hub-001.tendcloud.com/library/spark-driver:v2.1.0-kubernetes-0.3.1-1
	 phase: Succeeded
	 status: [ContainerStatus(containerID=docker://5c5c821c482a1e35552adccb567020532b79244392374f25754f0050e6cd4c62, image=sz-pg-oam-docker-hub-001.tendcloud.com/library/spark-driver:v2.1.0-kubernetes-0.3.1-1, imageID=docker-pullable://sz-pg-oam-docker-hub-001.tendcloud.com/library/spark-driver@sha256:beb92a3e3f178e286d9e5baebdead88b5ba76d651f347ad2864bb6f8eda26f94, lastState=ContainerState(running=null, terminated=null, waiting=null, additionalProperties={}), name=spark-kubernetes-driver, ready=false, restartCount=0, state=ContainerState(running=null, terminated=ContainerStateTerminated(containerID=docker://5c5c821c482a1e35552adccb567020532b79244392374f25754f0050e6cd4c62, exitCode=0, finishedAt=2017-09-14T06:59:11Z, message=null, reason=Completed, signal=null, startedAt=null, additionalProperties={}), waiting=null, additionalProperties={}), additionalProperties={})]
2017-09-14 14:59:12 INFO  LoggingPodStatusWatcherImpl:54 - Container final statuses:


	 Container name: spark-kubernetes-driver
	 Container image: sz-pg-oam-docker-hub-001.tendcloud.com/library/spark-driver:v2.1.0-kubernetes-0.3.1-1
	 Container state: Terminated
	 Exit code: 0
2017-09-14 14:59:12 INFO  Client:54 - Application spark-pi finished.
</code></pre>

<p>从日志中可以看到任务运行的状态信息。</p>

<p>使用下面的命令可以看到 kubernetes 启动的 Pod 信息：</p>

<pre><code class="language-bash">kubectl --namespace spark-cluster get pods -w
</code></pre>

<p>将会看到 <code>spark-driver</code> 和 <code>spark-exec</code> 的 Pod 信息。</p>

<h2 id="依赖管理">依赖管理</h2>

<p>上文中我们在运行测试程序时，命令行中指定的 jar 文件已包含在 docker 镜像中，是不是说我们每次提交任务都需要重新创建一个镜像呢？非也！如果真是这样也太麻烦了。</p>

<h4 id="创建-resource-staging-server">创建 resource staging server</h4>

<p>为了方便用户提交任务，不需要每次提交任务的时候都创建一个镜像，我们使用了 <strong>resource staging server</strong> 。</p>

<pre><code class="language-bash">kubectl create -f conf/kubernetes-resource-staging-server.yaml
</code></pre>

<p>我们同样将其部署在 <code>spark-cluster</code> namespace 下，该 yaml 文件见 <a href="https://github.com/rootsongjc/kubernetes-handbook">kubernetes-handbook</a> 的 <code>manifests/spark-with-kubernetes-native-scheduler</code> 目录。</p>

<h4 id="优化">优化</h4>

<p>其中有一点需要优化，在使用下面的命令提交任务时，使用</p>

<pre><code class="language-ini">--conf spark.kubernetes.resourceStagingServer.uri
</code></pre>

<p>参数指定 <em>resource staging server</em> 地址，用户不应该关注 <em>resource staging server</em> 究竟运行在哪台宿主机上，可以使用下面两种方式实现：</p>

<ul>
<li>使用 <code>nodeSelector</code> 将 <em>resource staging server</em> 固定调度到某一台机器上，该地址依然使用宿主机的 IP 地址</li>
<li>改变 <code>spark-resource-staging-service</code> service 的 type 为 <strong>ClusterIP</strong>， 然后使用 <strong>Ingress</strong> 将其暴露到集群外部，然后加入的内网 DNS 里，用户使用 DNS 名称指定 <em>resource staging server</em> 的地址。</li>
</ul>

<p>然后可以执行下面的命令来提交本地的 jar 到 kubernetes 上运行。</p>

<pre><code class="language-bash">./spark-submit \
  --deploy-mode cluster \
  --class org.apache.spark.examples.SparkPi \
  --master k8s://https://172.20.0.113:6443 \
  --kubernetes-namespace spark-cluster \
  --conf spark.kubernetes.authenticate.driver.serviceAccountName=spark \
  --conf spark.executor.instances=5 \
  --conf spark.app.name=spark-pi \
  --conf spark.kubernetes.driver.docker.image=sz-pg-oam-docker-hub-001.tendcloud.com/library/spark-driver:v2.1.0-kubernetes-0.3.1-1 \
  --conf spark.kubernetes.executor.docker.image=sz-pg-oam-docker-hub-001.tendcloud.com/library/spark-executor:v2.1.0-kubernetes-0.3.1-1 \
  --conf spark.kubernetes.initcontainer.docker.image=sz-pg-oam-docker-hub-001.tendcloud.com/library/spark-init:v2.1.0-kubernetes-0.3.1-1 \
  --conf spark.kubernetes.resourceStagingServer.uri=http://172.20.0.114:31000 \
  ../examples/jars/spark-examples_2.11-2.2.0-k8s-0.4.0-SNAPSHOT.jar
</code></pre>

<p>该命令将提交本地的 <code>../examples/jars/spark-examples_2.11-2.2.0-k8s-0.4.0-SNAPSHOT.jar</code> 文件到 <strong>resource staging server</strong>，executor 将从该 server 上获取 jar 包并运行，这样用户就不需要每次提交任务都编译一个镜像了。</p>

<p><a href="https://apache-spark-on-k8s.github.io/userdocs/running-on-kubernetes.html#dependency-management">详见 Dependency</a></p>

<h4 id="设置-hdfs-用户">设置 HDFS 用户</h4>

<p>如果 Hadoop 集群没有设置 kerbros 安全认证的话，在指定 <code>spark-submit</code> 的时候可以通过指定如下四个环境变量， 设置 Spark 与 HDFS 通信使用的用户：</p>

<pre><code class="language-ini">  --conf spark.kubernetes.driverEnv.SPARK_USER=hadoop 
  --conf spark.kubernetes.driverEnv.HADOOP_USER_NAME=hadoop 
  --conf spark.executorEnv.HADOOP_USER_NAME=hadoop 
  --conf spark.executorEnv.SPARK_USER=hadoop 
</code></pre>

<p>使用 hadoop 用户提交本地 jar 包的命令示例：</p>

<pre><code class="language-bash">./spark-submit \
  --deploy-mode cluster \
  --class com.talkingdata.alluxio.hadooptest \
  --master k8s://https://172.20.0.113:6443 \
  --kubernetes-namespace spark-cluster \
  --conf spark.kubernetes.driverEnv.SPARK_USER=hadoop \
  --conf spark.kubernetes.driverEnv.HADOOP_USER_NAME=hadoop \
  --conf spark.executorEnv.HADOOP_USER_NAME=hadoop \
  --conf spark.executorEnv.SPARK_USER=hadoop \
  --conf spark.kubernetes.authenticate.driver.serviceAccountName=spark \
  --conf spark.executor.instances=5 \
  --conf spark.app.name=spark-pi \
  --conf spark.kubernetes.driver.docker.image=sz-pg-oam-docker-hub-001.tendcloud.com/library/spark-driver:v2.1.0-kubernetes-0.3.1-1 \
  --conf spark.kubernetes.executor.docker.image=sz-pg-oam-docker-hub-001.tendcloud.com/library/spark-executor:v2.1.0-kubernetes-0.3.1-1 \
  --conf spark.kubernetes.initcontainer.docker.image=sz-pg-oam-docker-hub-001.tendcloud.com/library/spark-init:v2.1.0-kubernetes-0.3.1-1 \
  --conf spark.kubernetes.resourceStagingServer.uri=http://172.20.0.114:31000 \
~/Downloads/tendcloud_2.10-1.0.jar
</code></pre>

<p>详见：<a href="https://github.com/apache-spark-on-k8s/spark/issues/408">https://github.com/apache-spark-on-k8s/spark/issues/408</a></p>

<h2 id="参考">参考</h2>

<ul>
<li><a href="http://lxw1234.com/archives/2015/12/593.htm">Spark动态资源分配-Dynamic Resource Allocation</a></li>
<li><a href="https://apache-spark-on-k8s.github.io/userdocs/running-on-kubernetes.html">Running Spark on Kubernetes</a></li>
<li><a href="https://issues.apache.org/jira/browse/SPARK-18278">Apache Spark Jira Issue - 18278 - SPIP: Support native submission of spark jobs to a kubernetes cluster</a></li>
<li><a href="https://github.com/kubernetes/kubernetes/issues/34377">Kubernetes Github Issue - 34377 Support Spark natively in Kubernetes</a></li>
<li><a href="https://github.com/kubernetes/kubernetes/tree/master/examples/spark">Kubernetes example spark</a></li>
<li><a href="https://github.com/rootsongjc/spark-on-kubernetes">jimysong.io - spark-on-k8s</a></li>
</ul>

            </article>

            <ul class="pager blog-pager">
                
                <li class="previous">
                    <a href="https://jimmysong.io/posts/3-things-every-cto-should-know-about-kubernetes/" data-toggle="tooltip" data-placement="top" title="每位CTO都该知道的关于kubernetes的三件事">&larr; Previous Post</a>
                </li>
                 
                <li class="next">
                    <a href="https://jimmysong.io/posts/high-level-cloud-native-from-kevin-hoffman/" data-toggle="tooltip" data-placement="top" title="High Level Cloud Native From Kevin Hoffman">Next Post &rarr;</a>
                </li>
                
            </ul>
            
            <div>
                 
                <h2>See Also</h2>
                <ul>
                    
                    <li><a href="/posts/3-things-every-cto-should-know-about-kubernetes/">每位CTO都该知道的关于kubernetes的三件事</a></li>
                    
                    <li><a href="/posts/kubectl-user-authentication-authorization/">kubectl的用户认证授权</a></li>
                    
                    <li><a href="/posts/migrating-hadoop-yarn-to-kubernetes/">迁移传统应用到Kubernetes步骤详解——以Hadoop YARN为例</a></li>
                    
                    <li><a href="/posts/kubernetes-tls-bootstrapping/">Kubernetes TLS bootstrap引导程序</a></li>
                    
                    <li><a href="/posts/linkerd-user-guide/">微服务管理框架service mesh——Linkerd安装试用笔记</a></li>
                    
                </ul>
                
            </div>
            
            
            
            
<div>
    <section id="datecount">
        <h4 id="date"> Thu Sep 14, 2017</h4>
    </section>
    <h5 id="wc">4200 Words|Read in about 9 Min</h5>
    <h5 id="tags">Tags: 
        
        <a href="https://jimmysong.io/tags/kubernetes/">kubernetes</a> &nbsp;
        
        <a href="https://jimmysong.io/tags/spark/">spark</a> &nbsp;
        
        <a href="https://jimmysong.io/tags/big-data/">big-data</a> &nbsp;
    </h5>
</div>

            
            </div>
            
            
        </div>
    </div>
    </section>
</div>

    <footer>
  <div class="container">
    <div class="row">
      <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
        <ul class="list-inline text-center footer-links">
        <img src="https://ws1.sinaimg.cn/large/00704eQkly1fs0lebokxaj30a004gq44.jpg">
          
              <li>
                <a href="mailto:jimmysong@jimmysong.io" title="Email me">
                  <span class="fa-stack fa-lg">
                    <i class="fa fa-circle fa-stack-2x"></i>
                    <i class="fa fa-envelope fa-stack-1x fa-inverse"></i>
                  </span>
                </a>
              </li>
              <li>
                <a href="https://www.facebook.com/jimmysongio" title="Facebook">
                  <span class="fa-stack fa-lg">
                    <i class="fa fa-circle fa-stack-2x"></i>
                    <i class="fa fa-facebook fa-stack-1x fa-inverse"></i>
                  </span>
                </a>
              </li>
              <li>
                <a href="https://github.com/rootsongjc" title="GitHub">
                  <span class="fa-stack fa-lg">
                    <i class="fa fa-circle fa-stack-2x"></i>
                    <i class="fa fa-github fa-stack-1x fa-inverse"></i>
                  </span>
                </a>
              </li>
              <li>
                <a href="https://twitter.com/jimmysongio" title="Twitter">
                  <span class="fa-stack fa-lg">
                    <i class="fa fa-circle fa-stack-2x"></i>
                    <i class="fa fa-twitter fa-stack-1x fa-inverse"></i>
                  </span>
                </a>
              </li>
              <li>
                <a href="https://linkedin.com/in/jimmysongio" title="LinkedIn">
                  <span class="fa-stack fa-lg">
                    <i class="fa fa-circle fa-stack-2x"></i>
                    <i class="fa fa-linkedin fa-stack-1x fa-inverse"></i>
                  </span>
                </a>
              </li>
          
          <li>
            <a href="https://jimmysong.io/index.xml" title="RSS">
              <span class="fa-stack fa-lg">
                <i class="fa fa-circle fa-stack-2x"></i>
                <i class="fa fa-rss fa-stack-1x fa-inverse"></i>
              </span>
            </a>
          </li>
          
        </ul>
        <p class="credits copyright text-muted">
        &copy;2017-2018
          
            
              <a href="https://jimmysong.io">Jimmy Song(宋净超)</a>
            
          
          
          
            &nbsp;&bull;&nbsp;
            <a href="https://jimmysong.io/">Jimmy Song</a>
          
        </p>
        <p class="credits theme-by text-muted">
        <a href="https://servicemesher.github.io">ServiceMesher</a>&nbsp;&bull;&nbsp;<a href="https://dataikudss.com">dataikudss.com</a>&nbsp;&bull;&nbsp;<a href="https://cloudnativego.com">cloudnativego.com</a>
        </p>

        
        <p class="credits theme-by text-muted">
          <a href="http://gohugo.io">Hugo v0.40</a> powered &nbsp;&bull;&nbsp; Theme by <a href="http://deanattali.com/beautiful-jekyll/">Beautiful Jekyll</a> adapted to <a href="https://github.com/rootsongjc/beautifulhugo">Beautiful Hugo</a>
          
        </p>
      </div>
    </div>
  </div>
</footer>


<script src="https://res.cloudinary.com/jimmysong/raw/upload/rootsongjc-hugo/bootstrap.min.js"></script>
<script src="https://res.cloudinary.com/jimmysong/raw/upload/rootsongjc-hugo/photoswipe-ui-default.min.js"></script>
<script src="https://res.cloudinary.com/jimmysong/raw/upload/rootsongjc-hugo/photoswipe.min.js"></script>
<script src="https://res.cloudinary.com/jimmysong/raw/upload/rootsongjc-hugo/auto-render.min.js"></script>
<script src="https://res.cloudinary.com/jimmysong/raw/upload/rootsongjc-hugo/main.js"></script>
<script src="https://res.cloudinary.com/jimmysong/raw/upload/rootsongjc-hugo/prism.js"></script>
<script src="https://res.cloudinary.com/jimmysong/raw/upload/rootsongjc-hugo/katex.min.js"></script>
<script> renderMathInElement(document.body); </script>







  </body>
</html>

